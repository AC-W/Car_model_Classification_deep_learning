# -*- coding: utf-8 -*-
"""DVM Car dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qvWQrzNvGEKA3yolo3M7N5yFKlvRAR2Z
"""

!wget https://www.dropbox.com/s/ohfv6eq67x1z7gm/resized_DVM_v2.zip?dl=0

!unzip resized_DVM_v2.zip?dl=0

import torch
from torch import nn, optim
from torch.optim.lr_scheduler import LambdaLR
from torch.autograd import Variable, Function
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as tr
from torchvision import models
from torch.nn import functional as F
import time
from IPython.display import clear_output

from matplotlib import pyplot as plt
from PIL import Image
import os, random, math
from scipy.io import loadmat

class DVM(Dataset):
  def __init__(self,root,transform=None,train=True,img_per_class=30,year=2010,image_min = 30):
    super(DVM, self).__init__()
    self.transform = transform
    self.data_list = []
    self.car_dic = {}
    index = 0
    total_image_count = 0
    total_train_count = 0
    total_val_count = 0
    train_path = []
    val_path = []
    for car_brand in os.listdir(root):
      if car_brands.get(str(car_brand)) != None:
        brand_get = False
        root1 = os.path.join(root,car_brand)
        if os.path.isdir(root1):
          for car_model in os.listdir(root1):
            root2 = os.path.join(root1,car_model)
            for car_year in os.listdir(root2):
              try:
                if (int(car_year) > year):
                  new_entry = f'{car_brand}: {car_model} {car_year}'
                  root3 = os.path.join(root2,car_year)
                  image_count = 0
                  image_count_even = 0
                  image_count_odd = 0
                  train_temp_path = []
                  val_temp_path = []
                  train_temp_data_list = []
                  val_temp_data_list = []
                  for all in os.listdir(root3):
                    root4 = os.path.join(root3,all)
                    if os.path.isdir(root4):
                      count2 = 0
                      for images in os.listdir(root4):
                        image_count += 1
                        if (count2 %2 == 0) and (image_count_even < img_per_class):
                          image_count_even += 1
                          train_temp_path.append(os.path.join(root4,images))
                          train_temp_data_list.append((os.path.join(root4,images),index))
                        if (count2 %2 == 1) and (image_count_odd < img_per_class):
                          val_temp_path.append(os.path.join(root4,images))
                          val_temp_data_list.append((os.path.join(root4,images),index))
                          image_count_odd += 1
                        count2 += 1
                    else:
                      image_count += 0
                  if image_count >= image_min:
                    total_image_count += image_count
                    total_train_count += image_count_even
                    train_path += train_temp_path
                    val_path += val_temp_path
                    total_val_count += image_count_odd
                    self.car_dic[index] = new_entry
                    if (train):
                      self.data_list += train_temp_data_list
                    else:
                      self.data_list += val_temp_data_list
                    brand_get = True
                    index += 1
              except:
                break
        if not brand_get:
          continue
          print(f'did not get {car_brand}')
    # print(train_path[0])
    # print(len(train_path))
    # print(len(val_path))

  def __len__(self):
    return len(self.data_list)
  
  def __getitem__(self, idx):
      data = self.data_list[idx]
      with Image.open(data[0]) as image:
          return self.transform(image),data[1]

def train_model(net,learning_rate,batch_size,num_epoch,train_loader,val_loader):
  total_start_time = time.time()
  criterion = nn.CrossEntropyLoss().to(device)
  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-6)
  best = 0
  # optimizer = torch.optim.Adam(net.parameters(),lr = learning_rate,weight_decay=1e-5)
  # exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)
  best_epoch = None
  last_epoch = None
  for epoch in range(num_epoch):
    clear_output()
    print(torch.cuda.get_device_name(torch.cuda.current_device()))
    gb = torch.cuda.memory_allocated(0)*1e-9
    print(f'Used: {gb:.2f} GB')
    print(f'Train Batch size: {len(train_loader)} Val Batch size: {len(val_loader)} Train size: {len(train_loader.sampler)} Val size: {len(val_loader.sampler)}')
    print(f'best epoch: {best_epoch}')
    print(f'last epoch: {last_epoch}')
    total_end_time = time.time()
    total_elapsed_time = total_end_time - total_start_time
    print(f'total time passed: {total_elapsed_time:.2f}s')
    print(f'current epoch: {epoch}')
    correct = 0
    start_time = time.time()
    net.train()
    for i , (images,labels) in enumerate(train_loader):
      images = images.to(device)
      labels = labels.to(device)

      optimizer.zero_grad()
      #Foward Pass
      outputs = net(images)
      loss = criterion(outputs,labels)
      #Back
      loss.backward()
      optimizer.step()
      _, result = torch.max(outputs,1)
      correct += result.eq(labels).sum()
      if(i % int(len(train_loader)/10) == 0) and i != 0:
        print(f'train step: {i*batch_size}/{len(train_loader.sampler)} train acc: {(correct/((i+1)*batch_size))*100}%')
    train_correct = (correct/len(train_loader.sampler))*100

    with torch.no_grad():
      net.eval()
      correct = 0
      for i , (images,labels) in enumerate(val_loader):
        
        images = images.to(device)
        labels = labels.to(device)

        outputs = net(images)
        _, result = torch.max(outputs,1)
        correct += result.eq(labels).sum()

      val_correct = (correct/len(val_loader.sampler))*100
      if best < val_correct:
        best = val_correct
        torch.save(new_net.state_dict(),'/content/drive/MyDrive/Models/bestModel1')
        end_time = time.time()
        elapsed_time = end_time - start_time
        best_epoch = "Epoch: {} Train: {:.2f}% Valid: {:.2f}% Time: {:.2f} seconds".format(epoch,train_correct,val_correct,elapsed_time)
      model_path = f'{epoch}:Acc:{int(val_correct)}%'
      torch.save(net.state_dict(), model_path)

      end_time = time.time()
      elapsed_time = end_time - start_time

      last_epoch = "Epoch: {} Train: {:.2f}% Valid: {:.2f}% Time: {:.2f} seconds".format(epoch,train_correct,val_correct,elapsed_time)
      clear_output()
      print(torch.cuda.get_device_name(torch.cuda.current_device()))
      gb = torch.cuda.memory_allocated(0)*1e-9
      print(f'Used: {gb:.2f} GB')
      print(f'Train Batch size: {len(train_loader)} Val Batch size: {len(val_loader)} Train size: {len(train_loader.sampler)} Val size: {len(val_loader.sampler)}')
      print(f'best epoch: {best_epoch}')
      print(f'last epoch: {last_epoch}')
      total_end_time = time.time()
      total_elapsed_time = total_end_time - total_start_time
      print(f'total time passed: {total_elapsed_time:.2f}s')
      print(f'current epoch: {epoch}')
      # exp_lr_scheduler.step()

root = "/content/resized_DVM"

f = open(f'{root}/car_brands.txt','r')
lines = f.readlines()
car_brands = {}
index = 0
for line in lines:
  car_brands[str.strip(str(line))] = index
  index += 1

train_trans = tr.Compose([
    tr.Resize((224)),
    tr.RandomHorizontalFlip(0.5),
    tr.RandomRotation(10),
    tr.ToTensor(),
    tr.Grayscale(3),
    tr.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
])

val_trans = tr.Compose([
    tr.Resize((224)),
    tr.ToTensor(),
    tr.Grayscale(3),
    tr.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
])

num_epoch = 100
lr = 0.0005
batch_size = 128
          
train_dataset = DVM(root,transform=train_trans,image_min=100,year=2010,img_per_class = 50)
val_dataset = DVM(root,transform=val_trans,image_min=100,year=2010,img_per_class = 5,train=False)

train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=2)
val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=batch_size,shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device = torch.cuda.current_device()
print(torch.cuda.get_device_name(torch.cuda.current_device()))

print(torch.cuda.memory_allocated(0))
new_net = models.resnet50(pretrained=True).to(device)
num_ftrs = new_net.fc.in_features
new_net.fc = nn.Linear(num_ftrs, 1513).to(device)

train_model(new_net,lr,batch_size,num_epoch,train_loader,val_loader)